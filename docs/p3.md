# stitp

## KeyPoint

- **Parallel Multi-Scale Networks with Deep Supervision for Hand Keypoint Detection** | CNN | [[arxiv]](https://arxiv.org/abs/2112.10275) | 是一个手关键点识别的算法，没有代码
- **Hand Keypoint Detection in Single Images using Multiview Bootstrapping** | 多视图引导训练 | [openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)| [open-mmlab/mmpose](https://github.com/open-mmlab/mmpose)
  - openPose: c++从底层实现的关键点识别库，代码开源但参考价值不大
  - mmpose: Python手（身体）关键点识别库，基于torch，有训练框架代码，可操作性高，也就是说我们使用这个框架实现一个效果相近方法相近的模型可能比较容易。但对于多模态的支持和代码的适用性未知，也就是说整活上限不高，不方便添加多模态。**其代码框架有很高参考价值**
- [CMU HandDB]([Hand Database - CMU Panoptic Dataset](http://domedb.perception.cs.cmu.edu)


## 单眼RGB-Mesh

- [FreiHAND Dataset | Papers With Code](https://paperswithcode.com/dataset/freihand) | 手部3D信息，多视角图片
  - 如果使用这个数据集，那大概率是基于 单眼RGB 和 MANO 算法，MANO是一个输出手部三维模型的框架
  - [(84条消息) 基于参数化模型(MANO)的手势姿态估计---全面剖析_mano模型_sooner高的博客-CSDN博客](https://blog.csdn.net/g11d111/article/details/115539407)

- **Cross-Attention of Disentangled Modalities for3D Human Mesh Recovery with Transformers** | MANO + attention | https://github.com/postech-ami/FastMETRO | 使用到 FreiHAND 
- **DART: Articulated Hand Model with DiverseAccessories and Rich Textures** | MANO+纹理 | [DART (dart2022.github.io)](https://dart2022.github.io/)
- **ACR: Attention Collaboration-based Regressorfor Arbitrary Two-Hand Reconstruction** | Tencent AI | attention处理遮挡交互+MANO| [InterHand2.6M dataset | InterHand2.6M (mks0601.github.io)](https://mks0601.github.io/InterHand2.6M/) & FreiHAND

## RGBD-Mesh

- [[ICCV 2021\] H2O: Two Hands Manipulating Objects for First Person Interaction Recognition (taeinkwon.com)](https://taeinkwon.com/projects/h2o/) | 很好很全的数据集，但是基于其的成果少，开源的没找到 | 也是基于MANO | 第一人称
- **ShaRPy: Shape Reconstruction and Hand Pose Estimation from RGB-D with Uncertainty** | H2O | 用于临床医学的高精度3D位置识别 | YOLACT-segmentation | MANO | 前帧加入预测

- **ContactPose: A Dataset of Grasps with Object Contact and Hand Pose** | [contactpose-official](https://contactpose.cc.gatech.edu) | 3d joint | hand-object contact | rgbd|[ContactPose Dataset | Papers With Code](https://paperswithcode.com/dataset/contactpose) | 类似H2O，但没有第一人称

## SMPL

- [SMPL论文解读和相关基础知识介绍 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/256358005)
- SMPL: a skinned multi-person linear model
- 人体参数化三维模型

## 问题

- MANO 的参数化过程是什么：关节到mesh的关系？
- MANO 的具体原理是什么？为什么要对手关节重建？
  - 读MANOpaper，看manopth的代码？？
- 推测：manopth 是使用模型的代码，没有训练模型，在DART中有训练模型

## 梳理

1. [Learning joint reconstruction of hands and manipulated objects (hassony2.github.io)](https://hassony2.github.io/obman) | CVPR19 | 
2. （1）中的MANO-Pytorch代码实现：[hassony2/manopth](https://github.com/hassony2/manopth)
3. [CPF: Learning a **C**ontact **P**otential **F**ield](https://lixiny.github.io/CPF/) | 对（1）在性能上的改进，可以同时建模手和物体，建立了一个交互的库
4. Embodied Hands: Modeling and Capturing Hands and Bodies Together | MANO 原论文

5. [基于MANO的3D手部姿态估计方法：3D Hand Shape and Pose from Images in the Wild - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/456929689)
6. [(86条消息) 基于参数化模型(MANO)的手势姿态估计---全面剖析_mano模型_sooner高的博客-CSDN博客](https://blog.csdn.net/g11d111/article/details/115539407) | 文章见 [DART (dart2022.github.io)](https://dart2022.github.io/) | code: [DART2022/DART](https://github.com/DART2022/DART)

### PKL内容

```
Key: hands_components     Type: <class 'numpy.ndarray'>
Key: f                    Type: <class 'numpy.ndarray'>
Key: J_regressor          Type: <class 'scipy.sparse.csc.csc_matrix'>
Key: kintree_table        Type: <class 'numpy.ndarray'>	               //向前动力学树（不包含指尖）
Key: J                    Type: <class 'numpy.ndarray'>
Key: bs_style             Type: <class 'str'>
Key: hands_coeffs         Type: <class 'numpy.ndarray'>
Key: weights              Type: <class 'numpy.ndarray'>
Key: posedirs             Type: <class 'numpy.ndarray'>
Key: hands_mean           Type: <class 'numpy.ndarray'>	
Key: v_template           Type: <class 'numpy.ndarray'>
Key: shapedirs            Type: <class 'chumpy.reordering.Select'>
Key: bs_type              Type: <class 'str'>
```

```
Key: hands_components     Shape: (45, 45)
Key: f                    Shape: (1538, 3)
Key: J_regressor          Shape: (16, 778)
Key: kintree_table        Shape: (2, 16)
Key: J                    Shape: (16, 3)
Key: hands_coeffs         Shape: (1554, 45)
Key: weights              Shape: (778, 16)
Key: posedirs             Shape: (778, 3, 135)
Key: hands_mean           Shape: (45,)
Key: v_template           Shape: (778, 3)
Key: shapedirs            Shape: (778, 3, 10)
```

- VB改变世界！[January 15, 2023【虚拟形象驱动 AI 算法】 - 简书 (jianshu.com)](https://www.jianshu.com/p/15b8d3a82fcc)

- CVPR 2022 [ihoi](https://judyye.github.io/ihoi/) | 用手势来辅助生成抓握物体 

  - [frankmocap](https://github.com/facebookresearch/frankmocap/) | 待观察 | encode&decode 生成参数

  - [detectron2](https://github.com/facebookresearch/detectron2) | meta AI | 分割 | 可能用于物体的 mask 生成 
  - [100DOH](https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/) | 手部位置检测 | [code](https://github.com/ddshan/hand_object_detector)